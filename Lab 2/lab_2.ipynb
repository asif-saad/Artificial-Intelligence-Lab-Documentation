{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Segment 1 – Supervised Learning\n",
        "<h2>What is Supervised Learning?\n",
        "Supervised learning is a type of machine learning where a model learns from labeled data to make predictions. The model is trained using input data (features) and corresponding outputs (labels) and aims to generalize patterns to make predictions on unseen data.\n",
        "\n",
        "<h2>Key Concepts in Supervised Learning\n",
        "Features (Inputs):\n",
        "\n",
        "<h2>The variables that the model uses to make predictions.\n",
        "\n",
        "<h2>Example: For house price prediction, features might include square footage, number of bedrooms, etc.\n",
        "\n",
        "\n",
        "<h2>Labels (Outputs):\n",
        "\n",
        "<h2>The target variable we want to predict.\n",
        "Example: The house price in a prediction task.\n",
        "\n",
        "\n",
        "<h2>Training:\n",
        "\n",
        "<h2>The process of feeding data to the model and adjusting its parameters to minimize errors.\n",
        "\n",
        "\n",
        "<h2>Generalization:\n",
        "\n",
        "<h2>The ability of the model to perform well on unseen data, not just the training data.\n",
        "\n",
        "\n",
        "<h2>Types of Supervised Learning\n",
        "Classification:\n",
        "<h2>The task of predicting categories or classes.\n",
        "Example: Is an email spam or not? (Classes: Spam, Not Spam)\n",
        "Code Example: Classifying Iris flower species.\n"
      ],
      "metadata": {
        "id": "7a8I-A3uS4Fo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a Random Forest Classifier\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "wNGIimZEUGsu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06f23f4e-30f9-455b-8cb9-afbdf6f00c28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Regression:\n",
        "The task of predicting continuous values.\n",
        "Example: Predicting house prices based on features.\n",
        "Code Example: Predicting house prices."
      ],
      "metadata": {
        "id": "lwRmiSAtS59d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Generate a synthetic regression dataset\n",
        "X, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a Linear Regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n"
      ],
      "metadata": {
        "id": "NC2TCjoMS6HG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94916189-4124-4c89-a9e8-027e403a48f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 103.47302683438758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Applications of Supervised Learning\n",
        "Natural Language Processing (NLP):\n",
        "\n",
        "<h2>Sentiment analysis: Classifying text as positive or negative.\n",
        "Spam detection: Determining whether an email is spam.\n",
        "Computer Vision:\n",
        "\n",
        "<h2>Image classification: Identifying objects in images (e.g., cats vs. dogs).\n",
        "Face recognition: Recognizing individuals in photos.\n",
        "Healthcare:\n",
        "\n",
        "<h2>Disease prediction: Predicting diseases based on symptoms or patient data.\n",
        "Medical imaging: Detecting anomalies in X-rays or MRIs.\n",
        "Finance:\n",
        "\n",
        "<h2>Credit risk analysis: Predicting the likelihood of loan default.\n",
        "Stock price prediction: Estimating future stock values.\n",
        "\n",
        "\n",
        "\n",
        "<h2>Supervised Learning Workflow\n",
        "Let’s walk through the general steps of supervised learning.\n",
        "\n",
        "<h2>Collect Data:\n",
        "\n",
        "<h2>Obtain labeled data (e.g., emails with spam/not spam labels).\n",
        "Preprocess Data:\n",
        "\n",
        "<h2>Clean the data and handle missing values.\n",
        "Split Data:\n",
        "\n",
        "<h2>Divide data into training, validation, and test sets.\n",
        "<h2>Train a Model:\n",
        "\n",
        "<h2>Use training data to teach the model to make predictions.\n",
        "<h2>Validate the Model:\n",
        "\n",
        "<h2>Evaluate performance on validation data and tune hyperparameters.\n",
        "<h2>Test the Model:\n",
        "\n",
        "<h2>Assess the model’s accuracy on unseen test data.\n",
        "\n",
        "\n",
        "Blog on Count Vectoriser: https://medium.com/swlh/understanding-count-vectorizer-5dd71530c1b\n",
        "\n",
        "\n",
        "<h2>Practical Example: Predicting Email Spam\n",
        "In this example, we’ll classify emails as spam or not spam using a supervised learning model."
      ],
      "metadata": {
        "id": "UJXcQgY2S6eN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Sample email dataset\n",
        "emails = [\n",
        "    \"Free money!!!\",\n",
        "    \"Win a free car now!\",\n",
        "    \"Important meeting tomorrow\",\n",
        "    \"Buy one get one free\",\n",
        "    \"Your invoice is due\",\n",
        "]\n",
        "labels = [1, 1, 0, 1, 0]  # 1 = Spam, 0 = Not Spam\n",
        "\n",
        "# Convert text to numerical features\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(emails)\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a Naive Bayes classifier\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "1gpfzCYdS6mh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "469f561e-1b7d-4b19-ad05-a0074951051f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Understanding Model Performance\n",
        "It’s important to evaluate how well your model is doing. Here are some common metrics:\n",
        "\n",
        "<h2>Accuracy: The percentage of correct predictions.\n",
        "Good for balanced datasets.\n",
        "Precision and Recall: Useful for imbalanced datasets.\n",
        "Precision: How many predicted positives are true positives.\n",
        "Recall: How many actual positives were correctly predicted.\n",
        "Code Example: Evaluating Precision and Recall"
      ],
      "metadata": {
        "id": "w2XKUqpKS6ws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Example predictions\n",
        "y_true = [1, 0, 1, 1, 0]  # True labels\n",
        "y_pred = [1, 0, 1, 0, 0]  # Predicted labels\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "id": "B6j8jyUhS624",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efa790ce-3ac6-438c-f2de-3cd79b54d759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 1.0\n",
            "Recall: 0.6666666666666666\n",
            "F1 Score: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Common Challenges in Supervised Learning\n",
        "Overfitting:\n",
        "\n",
        "<h2>The model performs well on training data but poorly on test data.\n",
        "\n",
        "\n",
        "<h2>Solution: Use regularization or more data.\n",
        "\n",
        "\n",
        "<h2>Underfitting:\n",
        "\n",
        "<h2>The model is too simple and doesn’t capture the patterns in the data.\n",
        "\n",
        "\n",
        "<h2>Solution: Use a more complex model.\n",
        "\n",
        "\n",
        "\n",
        "<h2>Class Imbalance:\n",
        "\n",
        "<h2>When one class dominates the dataset (e.g., 95% non-spam and 5% spam emails).\n",
        "\n",
        "\n",
        "<h2>Solution: Use techniques like oversampling the minority class.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<h2>SMOTE (Synthetic Minority Over-sampling Technique) is a technique used to address class imbalance in machine learning, especially when one class has significantly fewer samples than the other. This imbalance can lead to biased models that tend to predict the majority class more accurately, but perform poorly on the minority class.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<h2>How SMOTE Works:\n",
        "SMOTE generates synthetic samples for the minority class by creating new instances that are similar to existing ones, rather than by simply duplicating them. It works by selecting a minority class sample, finding its nearest neighbors, and then creating synthetic instances by interpolating between the sample and its neighbors.\n",
        "\n",
        "Introduction to SMOTE: https://medium.com/@corymaklin/synthetic-minority-over-sampling-technique-smote-7d419696b88c\n",
        "\n",
        "SMOTE and its Variants: https://medium.com/analytics-vidhya/handling-imbalanced-data-by-oversampling-with-smote-and-its-variants-23a4bf188eaf\n",
        "\n",
        "Handling Imbalanced Data with SMOTE: https://medium.com/@thecontentfarmblog/smote-a-powerful-technique-for-handling-imbalanced-data-2375ad46103c\n",
        "\n",
        "Consideration & Limitations: https://medium.com/@minjukim023/smote-practical-consideration-limitations-f0d926b661a8\n",
        "\n",
        "\n",
        "<h2>Code Example: Handling Class Imbalance"
      ],
      "metadata": {
        "id": "HiqHQk9QS6_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "# Example imbalanced dataset\n",
        "X_imbalanced = [[1], [2], [3], [4], [5], [6], [7], [8], [9]]\n",
        "y_imbalanced = [0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
        "\n",
        "# Apply SMOTE with reduced k_neighbors\n",
        "smote = SMOTE(random_state=42, k_neighbors=3)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_imbalanced, y_imbalanced)\n",
        "\n",
        "print(\"Original dataset size:\", Counter(y_imbalanced))\n",
        "print(\"Resampled dataset size:\", Counter(y_resampled))\n"
      ],
      "metadata": {
        "id": "0Z5UkwgSS7Ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ec5391-4f43-4a59-e2ab-174a6695fb68"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset size: Counter({0: 5, 1: 4})\n",
            "Resampled dataset size: Counter({0: 5, 1: 5})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Key Takeaways\n",
        "Supervised learning uses labeled data to train models.\n",
        "It can be used for classification or regression tasks.\n",
        "Data quality and proper evaluation are critical for success.\n",
        "Avoid overfitting and underfitting by tuning your model and using validation data."
      ],
      "metadata": {
        "id": "8ag4ghAXS7MG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2><u>Lecture Notes: Segment 2 – Importance of Datasets</u>\n",
        "\n",
        "<h2>What is a Dataset?\n",
        "\n",
        "<h2>A dataset is a collection of data points that are used to train and test machine learning models. Each data point in a dataset typically consists of:\n",
        "\n",
        "<h2>Features (Inputs): These are the variables used to make predictions (e.g., text, numbers, images).\n",
        "\n",
        "\n",
        "<h2>Labels (Outputs): These are the target variables that the model tries to predict.\n",
        "\n",
        "\n",
        "<h2>Why Are Datasets Important?\n",
        "The quality and characteristics of your dataset directly impact the performance of your machine learning model.\n",
        "\n",
        "<h2>Key Reasons:\n",
        "\n",
        "\n",
        "<h2>Training the Model:\n",
        "\n",
        "\n",
        "<h2>The model learns patterns and relationships from the dataset.\n",
        "A poor-quality dataset leads to inaccurate predictions.\n",
        "\n",
        "\n",
        "<h2>Generalization:\n",
        "\n",
        "<h2>A good dataset helps the model generalize well to unseen data.\n",
        "Overfitting occurs if the dataset doesn’t represent real-world scenarios.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<h2>Feature Representation:\n",
        "\n",
        "<h2>Features must be meaningful and relevant to the task. Irrelevant or redundant features can confuse the model.\n",
        "\n",
        "\n",
        "\n",
        "<h2>What Makes a Good Dataset?\n",
        "\n",
        "\n",
        "<h2>Relevance:\n",
        "\n",
        "<h2>The data should align with the task or problem you're solving.\n",
        "Example: For predicting stock prices, include financial indicators, not weather data.\n",
        "\n",
        "\n",
        "\n",
        "<h2>Diversity:\n",
        "\n",
        "<h2>Ensure the dataset covers all possible scenarios or variations.\n",
        "\n",
        "\n",
        "<h2>Example: For object detection, include images with different angles, lighting, and backgrounds.\n",
        "\n",
        "\n",
        "\n",
        "<h2>Quality:\n",
        "\n",
        "\n",
        "\n",
        "<h2>Remove errors, duplicates, and inconsistencies.\n",
        "\n",
        "\n",
        "<h2>Example: If labels are noisy (e.g., incorrect sentiment tags), the model will learn incorrect patterns.\n",
        "\n",
        "\n",
        "\n",
        "<h2>Size:\n",
        "\n",
        "<h2>The dataset should be large enough for the model to capture patterns.\n",
        "\n",
        "\n",
        "<h2>Example: Neural networks require more data compared to simpler models like linear regression.\n",
        "\n",
        "\n",
        "\n",
        "<h2>Balanced Classes:\n",
        "\n",
        "<h2>Avoid class imbalance where one category dominates.\n",
        "\n",
        "\n",
        "\n",
        "<h2>Example: If 90% of emails are \"Not Spam\" and 10% are \"Spam,\" the model might always predict \"Not Spam.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<h2>Types of Datasets\n",
        "\n",
        "\n",
        "<h2>Structured Data:\n",
        "\n",
        "<h2>Organized into rows and columns (e.g., spreadsheets, databases).\n",
        "\n",
        "\n",
        "<h2>Example: Sales records with features like product name, price, and quantity.\n",
        "\n",
        "\n",
        "\n",
        "<h2>Unstructured Data:\n",
        "\n",
        "<h2>Data that doesn’t follow a predefined structure (e.g., text, images, videos).\n",
        "\n",
        "\n",
        "<h2>Example: Tweets for sentiment analysis or photos for object recognition.\n",
        "\n",
        "\n",
        "<h2>Time-Series Data:\n",
        "\n",
        "<h2>Sequential data indexed by time (e.g., stock prices, weather data).\n",
        "\n",
        "\n",
        "<h2>Example: Temperature readings every hour.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<h2>Common Challenges with Datasets\n",
        "\n",
        "\n",
        "\n",
        "<h2>Class Imbalance:\n",
        "\n",
        "<h2>If one class is overrepresented, the model may ignore minority classes.\n",
        "\n",
        "\n",
        "<h2>Solution: Use oversampling (e.g., SMOTE) or undersampling techniques.\n",
        "\n",
        "\n",
        "<h2>Noisy Data:\n",
        "\n",
        "<h2>Data with incorrect labels or inconsistencies.\n",
        "\n",
        "\n",
        "<h2>Solution: Clean the data manually or use automated cleaning tools.\n",
        "\n",
        "\n",
        "<h2>Missing Data:\n",
        "\n",
        "<h2>Some features might have missing values.\n",
        "\n",
        "\n",
        "<h2>Solution: Fill missing values using techniques like mean imputation or predictive imputation.\n",
        "\n",
        "\n",
        "<h2>Bias:\n",
        "\n",
        "<h2>A dataset might reflect societal or sampling biases, leading to unfair predictions.\n",
        "\n",
        "\n",
        "<h2>Solution: Audit the dataset for fairness and ensure diverse representation.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<h2>Code Example: Exploring a Dataset\n",
        "We’ll use a built-in dataset from scikit-learn and explore its structure."
      ],
      "metadata": {
        "id": "_H4ogYezXLqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "\n",
        "# Create a DataFrame for better visualization\n",
        "data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "data['label'] = iris.target\n",
        "\n",
        "# Display the first few rows\n",
        "print(\"Dataset Preview:\")\n",
        "print(data.head())\n",
        "\n",
        "# Check class distribution\n",
        "print(\"\\nClass Distribution:\")\n",
        "print(data['label'].value_counts())\n"
      ],
      "metadata": {
        "id": "wmarz7WVS7Td",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06c47746-042f-43a0-9f90-16a20cfd5925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Preview:\n",
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
            "0                5.1               3.5                1.4               0.2   \n",
            "1                4.9               3.0                1.4               0.2   \n",
            "2                4.7               3.2                1.3               0.2   \n",
            "3                4.6               3.1                1.5               0.2   \n",
            "4                5.0               3.6                1.4               0.2   \n",
            "\n",
            "   label  \n",
            "0      0  \n",
            "1      0  \n",
            "2      0  \n",
            "3      0  \n",
            "4      0  \n",
            "\n",
            "Class Distribution:\n",
            "label\n",
            "0    50\n",
            "1    50\n",
            "2    50\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Code Example: Handling Missing Data\n",
        "Let’s simulate missing data and handle it."
      ],
      "metadata": {
        "id": "euudmzDfS7ay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a sample dataset with missing values\n",
        "data = pd.DataFrame({\n",
        "    \"Feature1\": [1, 2, np.nan, 4],\n",
        "    \"Feature2\": [np.nan, 2, 3, 4],\n",
        "    \"Label\": [0, 1, 0, 1]\n",
        "})\n",
        "\n",
        "print(\"Original Data:\")\n",
        "print(data)\n",
        "\n",
        "# Fill missing values with the mean\n",
        "data['Feature1'] = data['Feature1'].fillna(data['Feature1'].mean())\n",
        "data['Feature2'] = data['Feature2'].fillna(data['Feature2'].mean())\n",
        "\n",
        "print(\"\\nData After Handling Missing Values:\")\n",
        "print(data)"
      ],
      "metadata": {
        "id": "3F4OJMKES7gb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b456620-776d-49ba-c5ee-e677664232e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data:\n",
            "   Feature1  Feature2  Label\n",
            "0       1.0       NaN      0\n",
            "1       2.0       2.0      1\n",
            "2       NaN       3.0      0\n",
            "3       4.0       4.0      1\n",
            "\n",
            "Data After Handling Missing Values:\n",
            "   Feature1  Feature2  Label\n",
            "0  1.000000       3.0      0\n",
            "1  2.000000       2.0      1\n",
            "2  2.333333       3.0      0\n",
            "3  4.000000       4.0      1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Code Example: Class Imbalance\n",
        "Here’s how to identify and handle class imbalance using SMOTE."
      ],
      "metadata": {
        "id": "2mxECL3iS7nJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "# Simulate an imbalanced dataset\n",
        "X = [[i] for i in range(10)]\n",
        "y = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
        "\n",
        "print(\"Original Class Distribution:\", Counter(y))\n",
        "\n",
        "# Apply SMOTE to balance the dataset\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "print(\"Resampled Class Distribution:\", Counter(y_resampled))"
      ],
      "metadata": {
        "id": "xOQtU99yS7tO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Data Augmentation\n",
        "For smaller datasets, you can artificially expand the dataset using augmentation techniques.\n",
        "\n",
        "<h2>Text Data:\n",
        "\n",
        "<h2>Synonym replacement.\n",
        "Sentence shuffling.\n",
        "Adding noise.\n",
        "Image Data:\n",
        "\n",
        "<h2>Rotate, crop, or flip images.\n",
        "Adjust brightness or contrast.\n",
        "Code Example: Text Data Augmentation"
      ],
      "metadata": {
        "id": "3li8yJ1hS79B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import string\n",
        "\n",
        "# Original sentence\n",
        "sentence = \"Machine learning is amazing.\"\n",
        "\n",
        "# Synonym replacement\n",
        "synonyms = {\"amazing\": [\"awesome\", \"fantastic\", \"incredible\"]}\n",
        "\n",
        "# Replace one word with a synonym\n",
        "words = sentence.split()\n",
        "word_to_replace = \"amazing\"\n",
        "\n",
        "# Check each word without punctuation\n",
        "for i, word in enumerate(words):\n",
        "    stripped_word = word.strip(string.punctuation)  # Remove punctuation for comparison\n",
        "    if stripped_word == word_to_replace:\n",
        "        words[i] = random.choice(synonyms[word_to_replace]) + word[len(stripped_word):]  # Preserve punctuation\n",
        "\n",
        "augmented_sentence = \" \".join(words)\n",
        "print(\"Original Sentence:\", sentence)\n",
        "print(\"Augmented Sentence:\", augmented_sentence)\n"
      ],
      "metadata": {
        "id": "HyfoO2b7S8Et",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ecd2a2c-752b-46ba-bc3d-3b25473d1daf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Sentence: Machine learning is amazing.\n",
            "Augmented Sentence: Machine learning is awesome.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2><u>Lecture Notes: Segment 3 – Train/Dev/Test Splits</u>\n",
        "\n",
        "<h2>What Are Train/Dev/Test Splits?\n",
        "<h2>Machine learning models need to be evaluated carefully to ensure they perform well on unseen data. To achieve this, the dataset is divided into three distinct parts:\n",
        "\n",
        "<h2>Training Set: Used to teach the model. The model learns patterns and relationships in the data.\n",
        "Validation Set (Dev Set): Used to fine-tune the model, adjust hyperparameters, and evaluate its performance during development.\n",
        "Test Set: Used to evaluate the final model's performance on unseen data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<h2>Why Split the Dataset?\n",
        "Prevent Overfitting:\n",
        "\n",
        "<h2>Overfitting occurs when the model performs well on the training set but fails to generalize to new data.\n",
        "Proper splits ensure the model doesn't memorize training data but learns patterns.\n",
        "Assess Generalization:\n",
        "\n",
        "<h2>The validation and test sets help us measure how well the model generalizes to new, unseen data.\n",
        "Tune Hyperparameters:\n",
        "\n",
        "<h2>Use the validation set to find the best model settings (e.g., learning rate, depth of a decision tree).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<h2>How to Split the Dataset\n",
        "Common Splitting Ratios:\n",
        "Standard Ratio:\n",
        "Training: 70%\n",
        "Validation: 15%\n",
        "Test: 15%\n",
        "For Small Datasets:\n",
        "Training: 80%\n",
        "Validation: 10%\n",
        "Test: 10%\n",
        "For Time-Series Data:\n",
        "Splits are sequential (e.g., earlier data for training, later data for testing).\n",
        "Best Practices:\n",
        "Always shuffle the data before splitting (except for time-series data).\n",
        "Ensure that all splits have the same class distribution (stratified sampling).\n",
        "\n",
        "\n",
        "\n",
        "<h2>Code Example: Train/Dev/Test Splits with scikit-learn\n",
        "Let’s split a dataset into training, validation, and test sets."
      ],
      "metadata": {
        "id": "j513fsi0S8L-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split into training (70%) and temp (30%) sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Split temp set into validation (15%) and test (15%)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "print(\"Training set size:\", len(X_train))\n",
        "print(\"Validation set size:\", len(X_val))\n",
        "print(\"Test set size:\", len(X_test))\n"
      ],
      "metadata": {
        "id": "wAdmZV5DS8a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8221493-4b63-4e49-f163-7597dde53e26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 105\n",
            "Validation set size: 22\n",
            "Test set size: 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Visualizing the Split\n",
        "To better understand how the splits work, let’s visualize the distribution of data."
      ],
      "metadata": {
        "id": "6Tdj1XqGY717"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example class distribution\n",
        "classes = [\"Class 0\", \"Class 1\", \"Class 2\"]\n",
        "train_counts = [sum(y_train == i) for i in range(3)]\n",
        "val_counts = [sum(y_val == i) for i in range(3)]\n",
        "test_counts = [sum(y_test == i) for i in range(3)]\n",
        "\n",
        "# Bar plot\n",
        "plt.bar(classes, train_counts, label=\"Training Set\")\n",
        "plt.bar(classes, val_counts, label=\"Validation Set\", alpha=0.7)\n",
        "plt.bar(classes, test_counts, label=\"Test Set\", alpha=0.5)\n",
        "plt.legend()\n",
        "plt.title(\"Class Distribution Across Splits\")\n",
        "plt.xlabel(\"Classes\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "BjutjWlbY78t",
        "outputId": "25e2ec61-a7af-4f4a-a63d-14287721d147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Challenges in Train/Dev/Test Splits\n",
        "Data Leakage:\n",
        "\n",
        "<h2>Occurs when information from the test set is accidentally used during training.\n",
        "Example: Normalizing the entire dataset before splitting.\n",
        "Solution: Always split the data first, then preprocess each split separately.\n",
        "Imbalanced Datasets:\n",
        "\n",
        "<h2>When one class dominates the dataset, splitting randomly might lead to uneven class distributions.\n",
        "Solution: Use stratified sampling to maintain the class ratio across splits.\n",
        "Small Datasets:\n",
        "\n",
        "<h2>Splitting a small dataset reduces the amount of data available for training.\n",
        "Solution: Use cross-validation instead of a fixed split.\n",
        "\n",
        "\n",
        "\n",
        "<h2>Stratified Sampling Example\n",
        "Stratified sampling ensures that class proportions remain consistent across splits."
      ],
      "metadata": {
        "id": "ChtACDRIY8Es"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Simulated dataset with imbalanced classes\n",
        "X = np.array([[i] for i in range(100)])\n",
        "y = [0] * 90 + [1] * 10  # 90% Class 0, 10% Class 1\n",
        "\n",
        "# Stratified split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "\n",
        "print(\"Class Distribution in Training Set:\", np.bincount(y_train))\n",
        "print(\"Class Distribution in Test Set:\", np.bincount(y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9K-0PVNkY8Kj",
        "outputId": "64db9e47-823f-4b6a-ac37-0f17ba51d365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution in Training Set: [63  7]\n",
            "Class Distribution in Test Set: [27  3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Cross-Validation for Small Datasets\n",
        "Instead of a fixed split, cross-validation divides the dataset into k-folds and trains the model multiple times, using a different fold for validation each time.\n",
        "\n",
        "<h2>Code Example: k-Fold Cross-Validation"
      ],
      "metadata": {
        "id": "MAKq7A_ZY8Ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Simulated dataset\n",
        "X = np.random.rand(100, 2)\n",
        "y = np.random.randint(0, 2, size=100)\n",
        "\n",
        "# k-Fold Cross-Validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "model = LogisticRegression()\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    print(\"Fold Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WY01zWCY8YP",
        "outputId": "a7706ef0-907e-4abe-fd35-576c27c54881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold Accuracy: 0.45\n",
            "Fold Accuracy: 0.45\n",
            "Fold Accuracy: 0.55\n",
            "Fold Accuracy: 0.25\n",
            "Fold Accuracy: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Train/Dev/Test Splits for Time-Series Data\n",
        "For time-series data, you cannot shuffle the dataset because the temporal order is essential. Splits must respect the time order.\n",
        "\n",
        "<h2>Code Example: Sequential Splits for Time-Series Data"
      ],
      "metadata": {
        "id": "QkczHmZuY8e_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Simulated time-series data\n",
        "time_data = np.arange(100)\n",
        "target = np.sin(time_data / 10)\n",
        "\n",
        "# Sequential split\n",
        "train_size = int(0.7 * len(time_data))\n",
        "X_train, X_test = time_data[:train_size], time_data[train_size:]\n",
        "y_train, y_test = target[:train_size], target[train_size:]\n",
        "\n",
        "print(\"Training Data:\", X_train[:5], \"->\", y_train[:5])\n",
        "print(\"Test Data:\", X_test[:5], \"->\", y_test[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dm0lm9usY8lW",
        "outputId": "c38cf41a-4142-4f0a-e05a-fdb59b86dfac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data: [0 1 2 3 4] -> [0.         0.09983342 0.19866933 0.29552021 0.38941834]\n",
            "Test Data: [70 71 72 73 74] -> [0.6569866  0.72896904 0.79366786 0.85043662 0.8987081 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Lecture Notes: Segment 4 – How to Build Your Own Dataset\n",
        "\n",
        "<h2>Introduction\n",
        "Building your own dataset is a critical step in machine learning, especially when you don’t have access to an existing dataset that suits your problem. A well-prepared dataset directly influences your model’s performance and generalization.\n",
        "\n",
        "<h2>In this segment, we’ll cover:\n",
        "\n",
        "<h2>How to define your problem and collect data.\n",
        "Methods for cleaning and preprocessing raw data.\n",
        "Annotating the dataset to provide labels.\n",
        "Splitting the dataset for training, validation, and testing.\n",
        "\n",
        "\n",
        "<h2>1. Define the Problem\n",
        "Before you begin, clearly define the task you want to solve.\n",
        "\n",
        "<h2>Examples of Problems:\n",
        "Text Classification: Determine the sentiment of a review (positive/negative).\n",
        "Object Detection: Identify objects in images (e.g., cars, people).\n",
        "Regression: Predict house prices based on features like size and location.\n",
        "Key Questions to Ask:\n",
        "What is the input (features)?\n",
        "What is the output (labels)?\n",
        "What kind of data will you collect (text, images, numbers)?\n",
        "How much data do you need?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<h2>2. Collect Data\n",
        "Once the problem is defined, collect raw data from sources like:\n",
        "\n",
        "<h2>APIs: Use public APIs to fetch structured data.\n",
        "Example: Twitter API for tweets, OpenWeather API for weather data.\n",
        "Web Scraping: Extract unstructured data from websites using libraries like `requests` and `BeautifulSoup`.\n",
        "Manual Data Entry: Enter small datasets manually (e.g., survey responses).\n",
        "Simulated Data: Generate synthetic data for controlled experiments.\n",
        "\n",
        "<h2>Code Example: Scraping Data Using `BeautifulSoup`"
      ],
      "metadata": {
        "id": "m21nhnKlY8s1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL of the website to scrape\n",
        "url = \"https://example.com/news\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Extract headlines from the webpage\n",
        "headlines = [h.text.strip() for h in soup.find_all('h2')]\n",
        "print(\"Sample Headlines:\", headlines[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UJ1H_ZHY8y8",
        "outputId": "3193f474-b4d5-45c5-bbc4-1178cce0d523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Headlines: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Code Example: Fetching Data Using an API"
      ],
      "metadata": {
        "id": "9gIR-44VY86b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Example: Fetch data from a public API\n",
        "url = \"https://api.openweathermap.org/data/2.5/weather\"\n",
        "params = {\n",
        "    \"q\": \"London\",\n",
        "    \"appid\": \"your_api_key\",  # Replace with your actual API key\n",
        "}\n",
        "\n",
        "response = requests.get(url, params=params)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    data = response.json()\n",
        "    print(\"City:\", data.get(\"name\", \"Unknown\"))\n",
        "    print(\"Weather:\", data[\"weather\"][0][\"description\"] if \"weather\" in data else \"No weather data\")\n",
        "    print(\"Temperature:\", data[\"main\"][\"temp\"], \"K\" if \"main\" in data else \"No temperature data\")\n",
        "else:\n",
        "    print(\"Error:\", response.status_code, \"-\", response.json().get(\"message\", \"Unknown error\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GlmDHf0Y9Aw",
        "outputId": "316a6783-3c6b-4704-9e4b-4a04d39b87e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: 401 - Invalid API key. Please see https://openweathermap.org/faq#error401 for more info.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>3. Clean and Preprocess the Data\n",
        "Raw data often contains noise, duplicates, or missing values that need to be cleaned.\n",
        "\n",
        "<h2>Steps to Clean Data:\n",
        "Remove Duplicates:\n",
        "Avoid redundant data points that can bias the model.\n",
        "Handle Missing Values:\n",
        "Replace missing values with mean/median for numerical data or a placeholder for text.\n",
        "Normalize Data:\n",
        "Convert text to lowercase, remove special characters, and standardize formats.\n",
        "Code Example: Cleaning Text Data"
      ],
      "metadata": {
        "id": "pKcmJc_TY9Ht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Example dataset\n",
        "data = pd.DataFrame({\n",
        "    \"Text\": [\"I love Python!\", \"Python is amazing!!!\", \"I love data science.\", None],\n",
        "    \"Label\": [1, 1, 1, 0],\n",
        "})\n",
        "\n",
        "# Drop missing values\n",
        "data = data.dropna()\n",
        "\n",
        "# Normalize text\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    return text\n",
        "\n",
        "data['Text'] = data['Text'].apply(clean_text)\n",
        "print(\"Cleaned Data:\")\n",
        "print(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9xnnlMPY9OP",
        "outputId": "746be72b-e4ec-4439-a0af-19cda0f74b63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Data:\n",
            "                  Text  Label\n",
            "0        i love python      1\n",
            "1    python is amazing      1\n",
            "2  i love data science      1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>4. Annotate the Data\n",
        "Annotations are labels that define the \"ground truth\" for supervised learning.\n",
        "\n",
        "<h2>Manual Annotation:\n",
        "Use tools like Doccano for text data.\n",
        "Use LabelImg for image data.\n",
        "Automated Annotation:\n",
        "Use rule-based or pre-trained models to pre-label the data, and then manually correct errors.\n",
        "Activity: Manual Annotation with Text\n",
        "Create a text dataset (e.g., product reviews).\n",
        "Label each review as \"Positive\" or \"Negative\".\n",
        "Code Example: Automated Annotation"
      ],
      "metadata": {
        "id": "xjxW_ok4Y9VN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load a pre-trained spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Sample sentences\n",
        "sentences = [\"Apple is a great company.\", \"The weather is terrible today.\"]\n",
        "\n",
        "# Annotate named entities\n",
        "for sentence in sentences:\n",
        "    doc = nlp(sentence)\n",
        "    for ent in doc.ents:\n",
        "        print(f\"Entity: {ent.text}, Label: {ent.label_}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQl0OSIcY9bs",
        "outputId": "8c333dc3-8af0-4b75-f6e3-d18692409065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entity: Apple, Label: ORG\n",
            "Entity: today, Label: DATE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>5. Split the Dataset\n",
        "After preparing the dataset, divide it into training, validation, and test sets.\n",
        "\n",
        "<h2>Code Example: Splitting Data"
      ],
      "metadata": {
        "id": "mpr7WyatY9i0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Example dataset\n",
        "texts = [\"I love programming.\", \"Python is awesome.\", \"I hate bugs.\", \"Debugging is fun.\"]\n",
        "labels = [1, 1, 0, 1]  # 1 = Positive, 0 = Negative\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "print(\"Training Data:\", X_train)\n",
        "print(\"Test Data:\", X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfoBrs4BY9pl",
        "outputId": "8ae09146-af8b-44c1-d162-61b1d7d917ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data: ['I love programming.', 'I hate bugs.']\n",
            "Test Data: ['Python is awesome.', 'Debugging is fun.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>6. Store the Dataset\n",
        "Save your dataset in a format that can be easily loaded for training.\n",
        "\n",
        "<h2>File Formats:\n",
        "CSV: Use for tabular data.\n",
        "JSON: Use for hierarchical or nested data.\n",
        "Images: Store with filenames indicating labels (e.g., cat_01.jpg).\n",
        "Code Example: Save and Load a Dataset"
      ],
      "metadata": {
        "id": "ualfwgskY9wp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Save dataset to CSV\n",
        "data.to_csv(\"dataset.csv\", index=False)\n",
        "\n",
        "# Load dataset\n",
        "loaded_data = pd.read_csv(\"dataset.csv\")\n",
        "print(\"Loaded Data:\")\n",
        "print(loaded_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_NJm9zmY94c",
        "outputId": "6ffb68f4-db01-4f74-c051-97d76d655311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Data:\n",
            "                  Text  Label\n",
            "0        i love python      1\n",
            "1    python is amazing      1\n",
            "2  i love data science      1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Lecture Notes: Segment 5 – Preprocessing and Feature Selection Using NLTK, scikit-learn, and spaCy\n",
        "\n",
        "<h2>Introduction\n",
        "Before using data to train machine learning models, we need to prepare it. Preprocessing involves cleaning and transforming raw data into a usable format. For text data, preprocessing includes tasks like tokenization, stopword removal, and converting text into numerical features.\n",
        "\n",
        "<h2>In this segment, we’ll cover:\n",
        "\n",
        "<h2>What is preprocessing and why it’s important.\n",
        "Preprocessing text data using NLTK, scikit-learn, and spaCy.\n",
        "Feature selection: Converting text into numerical features (TF-IDF, Bag of Words).\n",
        "Practical examples and activities for hands-on learning.\n",
        "\n",
        "\n",
        "\n",
        "<h2>1. What Is Preprocessing?\n",
        "Preprocessing is the process of cleaning and transforming raw data to make it usable for machine learning. It’s crucial because:\n",
        "\n",
        "<h2>Raw data is often noisy and inconsistent.\n",
        "Machine learning models work with numerical data, so text needs to be converted into numbers.\n",
        "Proper preprocessing ensures the model learns meaningful patterns.\n",
        "\n",
        "\n",
        "<h2>2. Common Text Preprocessing Steps\n",
        "Tokenization:\n",
        "\n",
        "<h2>Splitting text into smaller units like words or sentences.\n",
        "Example: \"I love Python!\" → [\"I\", \"love\", \"Python\", \"!\"]\n",
        "Stopword Removal:\n",
        "\n",
        "<h2>Removing common words like \"and\", \"the\", and \"is\" that do not carry much meaning.\n",
        "Stemming:\n",
        "\n",
        "<h2>Reducing words to their root forms.\n",
        "Example: \"running\", \"runner\" → \"run\"\n",
        "Lemmatization:\n",
        "\n",
        "<h2>Converting words to their base forms using vocabulary and grammar rules.\n",
        "Example: \"running\" → \"run\"\n",
        "Lowercasing:\n",
        "\n",
        "<h2>Converting all text to lowercase to reduce redundancy.\n",
        "Removing Punctuation:\n",
        "\n",
        "<h2>Eliminating characters like \".\", \",\", and \"!\".\n",
        "Converting Text to Numbers:\n",
        "\n",
        "<h2>Using techniques like Bag of Words (BoW) or TF-IDF to represent text numerically.\n",
        "\n",
        "<h2>3. Preprocessing Text with NLTK\n",
        "Code Example: Tokenization and Stopword Removal"
      ],
      "metadata": {
        "id": "8MDFCV6SY9_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "# Download necessary resources\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Sample text\n",
        "text = \"Natural Language Processing is an exciting field of Artificial Intelligence!\"\n",
        "\n",
        "# Tokenization using Python's built-in regular expressions\n",
        "tokens = re.findall(r'\\b\\w+\\b', text)\n",
        "print(\"Tokens:\", tokens)\n",
        "\n",
        "# Stopword Removal\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "print(\"Filtered Tokens:\", filtered_tokens)\n"
      ],
      "metadata": {
        "id": "XCgEGFT8Y-Hy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9f7b22e-7587-45b0-8073-496e534eb1bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['Natural', 'Language', 'Processing', 'is', 'an', 'exciting', 'field', 'of', 'Artificial', 'Intelligence']\n",
            "Filtered Tokens: ['Natural', 'Language', 'Processing', 'exciting', 'field', 'Artificial', 'Intelligence']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Code Example: Stemming"
      ],
      "metadata": {
        "id": "Zc98K0H1n3WR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Initialize stemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Example words\n",
        "words = [\"running\", \"runner\", \"ran\", \"easily\", \"fairness\"]\n",
        "\n",
        "# Apply stemming\n",
        "stems = [stemmer.stem(word) for word in words]\n",
        "print(\"Stemmed Words:\", stems)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQWVUDH4n3d3",
        "outputId": "02999fdb-8f28-43f3-b79b-f931fc8d5d8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed Words: ['run', 'runner', 'ran', 'easili', 'fair']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Code Example: Lemmatization"
      ],
      "metadata": {
        "id": "8RMNE5efn3mP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download WordNet\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Example words\n",
        "words = [\"running\", \"runner\", \"better\", \"easily\", \"fairness\"]\n",
        "\n",
        "# Apply lemmatization\n",
        "lemmas = [lemmatizer.lemmatize(word) for word in words]\n",
        "print(\"Lemmatized Words:\", lemmas)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpaTdBgIn3tM",
        "outputId": "9ae75e9f-9765-4529-a7c7-b7832b310086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized Words: ['running', 'runner', 'better', 'easily', 'fairness']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>4. Preprocessing Text with spaCy\n",
        "Code Example: Tokenization and Lemmatization"
      ],
      "metadata": {
        "id": "a8jXpXhDn30o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Sample text\n",
        "text = \"Natural Language Processing is an exciting field of Artificial Intelligence!\"\n",
        "\n",
        "# Process text with spaCy\n",
        "doc = nlp(text)\n",
        "\n",
        "# Tokenization\n",
        "tokens = [token.text for token in doc]\n",
        "print(\"Tokens:\", tokens)\n",
        "\n",
        "# Lemmatization\n",
        "lemmas = [token.lemma_ for token in doc if not token.is_stop]\n",
        "print(\"Lemmas (without stopwords):\", lemmas)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFRUh7L4n36x",
        "outputId": "c8a45f31-4bed-48c6-eb95-aa044a48460d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['Natural', 'Language', 'Processing', 'is', 'an', 'exciting', 'field', 'of', 'Artificial', 'Intelligence', '!']\n",
            "Lemmas (without stopwords): ['Natural', 'Language', 'Processing', 'exciting', 'field', 'Artificial', 'Intelligence', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code Example: Named Entity Recognition"
      ],
      "metadata": {
        "id": "DmVqWzh7n4Cu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract named entities\n",
        "for ent in doc.ents:\n",
        "    print(f\"Entity: {ent.text}, Label: {ent.label_}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuPUuFmmn4JV",
        "outputId": "533539e2-6d21-496d-8bd2-b84526a8a6d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entity: Artificial Intelligence, Label: ORG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>5. Feature Selection\n",
        "After preprocessing, the text must be converted into a numerical format that machine learning models can understand. Common techniques include:\n",
        "\n",
        "<h2>Bag of Words (BoW):\n",
        "\n",
        "<h2>Represents text as a collection of word counts.\n",
        "Example: \"I love Python\" → {\"I\": 1, \"love\": 1, \"Python\": 1}\n",
        "TF-IDF (Term Frequency - Inverse Document Frequency):\n",
        "\n",
        "<h2>Weighs words based on how important they are in a document relative to a collection of documents.\n",
        "Code Example: Bag of Words Using scikit-learn"
      ],
      "metadata": {
        "id": "zEPVVB9on4S-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Sample text data\n",
        "corpus = [\n",
        "    \"I love programming in Python.\",\n",
        "    \"Python is great for machine learning.\",\n",
        "    \"I love machine learning and natural language processing.\"\n",
        "]\n",
        "\n",
        "# Create a Bag of Words model\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "\n",
        "print(\"Feature Names:\", vectorizer.get_feature_names_out())\n",
        "print(\"Bag of Words Matrix:\\n\", X.toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bmr56lJmn4aY",
        "outputId": "3d2aeefa-8b71-40bf-8dff-0df4389f2166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Names: ['and' 'for' 'great' 'in' 'is' 'language' 'learning' 'love' 'machine'\n",
            " 'natural' 'processing' 'programming' 'python']\n",
            "Bag of Words Matrix:\n",
            " [[0 0 0 1 0 0 0 1 0 0 0 1 1]\n",
            " [0 1 1 0 1 0 1 0 1 0 0 0 1]\n",
            " [1 0 0 0 0 1 1 1 1 1 1 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Code Example: TF-IDF Using scikit-learn"
      ],
      "metadata": {
        "id": "4ng8QoEZS8mV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Create a TF-IDF model\n",
        "tfidf = TfidfVectorizer()\n",
        "X_tfidf = tfidf.fit_transform(corpus)\n",
        "\n",
        "print(\"Feature Names:\", tfidf.get_feature_names_out())\n",
        "print(\"TF-IDF Matrix:\\n\", X_tfidf.toarray())"
      ],
      "metadata": {
        "id": "N2-Ll3ubS8ue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1bb2487-387a-4371-c14a-e7d15f4b2438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Names: ['and' 'for' 'great' 'in' 'is' 'language' 'learning' 'love' 'machine'\n",
            " 'natural' 'processing' 'programming' 'python']\n",
            "TF-IDF Matrix:\n",
            " [[0.         0.         0.         0.5628291  0.         0.\n",
            "  0.         0.42804604 0.         0.         0.         0.5628291\n",
            "  0.42804604]\n",
            " [0.         0.45954803 0.45954803 0.         0.45954803 0.\n",
            "  0.34949812 0.         0.34949812 0.         0.         0.\n",
            "  0.34949812]\n",
            " [0.41756662 0.         0.         0.         0.         0.41756662\n",
            "  0.31757018 0.31757018 0.31757018 0.41756662 0.41756662 0.\n",
            "  0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>6. Combining Preprocessing Steps\n",
        "You can combine multiple preprocessing steps into a pipeline.\n",
        "\n",
        "<h2>Code Example: Custom Preprocessing Pipeline"
      ],
      "metadata": {
        "id": "rTPHY1_MS83m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "\n",
        "# Custom preprocessing function\n",
        "def preprocess_text(text):\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    # Tokenization using regular expressions\n",
        "    tokens = re.findall(r'\\b\\w+\\b', text)\n",
        "    # Remove stopwords\n",
        "    tokens = [word for word in tokens if word not in ENGLISH_STOP_WORDS]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Apply preprocessing to a dataset\n",
        "corpus = [\n",
        "    \"I love programming in Python!\",\n",
        "    \"Python is great for machine learning.\",\n",
        "    \"Natural language processing is amazing.\"\n",
        "]\n",
        "\n",
        "preprocessed_corpus = [preprocess_text(doc) for doc in corpus]\n",
        "print(\"Preprocessed Corpus:\", preprocessed_corpus)\n",
        "\n",
        "# Convert to TF-IDF features\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(preprocessed_corpus)\n",
        "print(\"TF-IDF Matrix:\\n\", X.toarray())\n"
      ],
      "metadata": {
        "id": "KUXA_81XS8_2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94d47ddb-3d21-4af5-f339-43b0ad4cc54e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed Corpus: ['love programming python', 'python great machine learning', 'natural language processing amazing']\n",
            "TF-IDF Matrix:\n",
            " [[0.         0.         0.         0.         0.62276601 0.\n",
            "  0.         0.         0.62276601 0.4736296 ]\n",
            " [0.         0.52863461 0.         0.52863461 0.         0.52863461\n",
            "  0.         0.         0.         0.40204024]\n",
            " [0.5        0.         0.5        0.         0.         0.\n",
            "  0.5        0.5        0.         0.        ]]\n"
          ]
        }
      ]
    }
  ]
}